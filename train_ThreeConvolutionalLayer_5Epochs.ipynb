{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_ThreeConvolutionalLayer_5Epochs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoReveriano/Facial-Expression-Recognition/blob/Version-4/train_ThreeConvolutionalLayer_5Epochs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "K3dpKNWbTejk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Original Model"
      ]
    },
    {
      "metadata": {
        "id": "RaUenXFMUAPB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Train The Dataset"
      ]
    },
    {
      "metadata": {
        "id": "1U1nFtUcTluL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Necessary Libaries"
      ]
    },
    {
      "metadata": {
        "id": "SOUiEvwPT07C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4c9593b-c1a9-4192-e4b3-b75a164c1da3"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time \n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.core import Dense, Dropout, Flatten, Activation"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "dBEOBGT6Ttvk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Check for GPU"
      ]
    },
    {
      "metadata": {
        "id": "c4YAJd50UEvv",
        "colab_type": "code",
        "outputId": "68aa4ed6-7ca5-4555-e2a6-80d5ce10fd97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "sess = tf.Session(config=config)\n",
        "keras.backend.set_session(sess)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "80EtH_BmU4_N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Select Settings"
      ]
    },
    {
      "metadata": {
        "id": "VNuX3XDlVBSz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = 7\n",
        "batch_size = 256\n",
        "epochs = 5\n",
        "VERBOSE = 1\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kQL_8KQKVEiz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Process Images"
      ]
    },
    {
      "metadata": {
        "id": "J0GrNNwZVNjW",
        "colab_type": "code",
        "outputId": "e998fdcc-28b4-489f-947d-c148d1c8ec2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "startTime = time.time()\n",
        "start = time.time() \n",
        "with tf.device('/GPU:0'):\n",
        "  with open(\"fer2013.csv\") as f:\n",
        "      content = f.readlines()\n",
        "  lines = np.array(content)\n",
        "  num_of_instances = lines.size\n",
        "end = time.time()\n",
        "print(\"Number of Images: \", num_of_instances)\n",
        "print(\"Pixel number of each image: \", len(lines[1].split(\",\")[1].split(\" \")))\n",
        "print(\"Time to prepare images = \", end-start)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Images:  35888\n",
            "Pixel number of each image:  2304\n",
            "Time to prepare images =  3.619169235229492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vMFyGiH0WkNG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the Model"
      ]
    },
    {
      "metadata": {
        "id": "7MAVCsHQHmx4",
        "colab_type": "code",
        "outputId": "ae3fb80e-8154-403b-a474-081a515c297b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "with tf.device('/GPU:0'):\n",
        "  x_train, y_train = [], []\n",
        "\n",
        "  for i in range(1, num_of_instances):\n",
        "      emotion, img, usage = lines[i].split(\",\")\n",
        "      val = img.split(\" \")\n",
        "      pixels = np.array(val, 'float32')\n",
        "      emotion = keras.utils.to_categorical(emotion, num_classes)\n",
        "      if 'Training' in usage:\n",
        "          y_train.append(emotion)\n",
        "          x_train.append(pixels)\n",
        "\n",
        "  x_train = np.array(x_train, 'float32')\n",
        "  y_train = np.array(y_train, 'float32')\n",
        "  x_train /= 255\n",
        "  x_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\n",
        "  x_train = x_train.astype('float32')\n",
        "  print(x_train.shape[0], 'train samples')\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  # Three Convolutional Layers\n",
        "  model.add(Conv2D(32, (3, 3),  activation='relu', padding='same', input_shape=(48, 48, 1)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.15))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.15))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.15))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "  # model.summary()\n",
        "  history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "\n",
        "  model_json = model.to_json()\n",
        "  with open(\"model.json\", \"w\") as json_file:\n",
        "      json_file.write(model_json)\n",
        "  model.save_weights(\"model.h5\")\n",
        "  print(\"Saved model to disk\")\n",
        "\n",
        "endTime= time.time()\n",
        "end = time.time()\n",
        "print(\"Total Runtime To Train Model = \", end-start)\n",
        "print(\"TOtal Runtime to Train Full Model = \", endTime - startTime)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28709 train samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 22967 samples, validate on 5742 samples\n",
            "Epoch 1/5\n",
            "22967/22967 [==============================] - 7s 305us/step - loss: 1.8108 - acc: 0.2494 - val_loss: 1.7321 - val_acc: 0.3060\n",
            "Epoch 2/5\n",
            "22967/22967 [==============================] - 3s 125us/step - loss: 1.6461 - acc: 0.3505 - val_loss: 1.5197 - val_acc: 0.4164\n",
            "Epoch 3/5\n",
            "22967/22967 [==============================] - 3s 129us/step - loss: 1.4939 - acc: 0.4230 - val_loss: 1.3916 - val_acc: 0.4638\n",
            "Epoch 4/5\n",
            "22967/22967 [==============================] - 3s 129us/step - loss: 1.3788 - acc: 0.4720 - val_loss: 1.2924 - val_acc: 0.5044\n",
            "Epoch 5/5\n",
            "22967/22967 [==============================] - 3s 125us/step - loss: 1.2885 - acc: 0.5072 - val_loss: 1.2509 - val_acc: 0.5228\n",
            "Saved model to disk\n",
            "Total Runtime To Train Model =  34.242395877838135\n",
            "TOtal Runtime to Train Full Model =  37.92611765861511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5SIzv0mWYQnf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Test the Dataset"
      ]
    },
    {
      "metadata": {
        "id": "E0OhxbLwYdCj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Import Necessary Libraries"
      ]
    },
    {
      "metadata": {
        "id": "HXUYU_9SYhma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import time\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o7KOQV0JQ_3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "d65a89bb-ead2-470b-b17b-0e55e7649fe3"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "num_classes = 7\n",
        "with tf.device('/GPU:0'):\n",
        "  with open(\"fer2013.csv\") as f:\n",
        "      content = f.readlines()\n",
        "  lines = np.array(content)\n",
        "  num_of_instances = lines.size\n",
        "\n",
        "  x_test, y_test = [], []\n",
        "\n",
        "  for i in range(1, num_of_instances):\n",
        "      emotion, img, usage = lines[i].split(\",\")\n",
        "      val = img.split(\" \")\n",
        "      pixels = np.array(val, 'float32')\n",
        "      emotion = keras.utils.to_categorical(emotion, num_classes)\n",
        "      if 'PublicTest' in usage:\n",
        "          y_test.append(emotion)\n",
        "          x_test.append(pixels)\n",
        "\n",
        "  x_test = np.array(x_test, 'float32')\n",
        "  y_test = np.array(y_test, 'float32')\n",
        "  x_test /= 255\n",
        "  x_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\n",
        "  x_test = x_test.astype('float32')\n",
        "  print(x_test.shape[0], 'test samples')\n",
        "\n",
        "  json_file = open('model.json', 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  loaded_model = model_from_json(loaded_model_json)\n",
        "  loaded_model.load_weights(\"model.h5\")\n",
        "  print(\"Loaded model from disk\")\n",
        "  loaded_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "def emotion_analysis(emotions):\n",
        "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "    y_pos = np.arange(len(objects))\n",
        "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
        "    plt.xticks(y_pos, objects)\n",
        "    plt.ylabel('percentage')\n",
        "    plt.title('emotion')\n",
        "    plt.show()\n",
        "\n",
        "evaluation = loaded_model.evaluate(x_test, y_test, batch_size=256, verbose=1)\n",
        "end = time.time()\n",
        "print('Summary: Loss over the test data set: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))\n",
        "print(\"Total Time in Testing Model: \", end-start)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3589 test samples\n",
            "Loaded model from disk\n",
            "3589/3589 [==============================] - 0s 82us/step\n",
            "Summary: Loss over the test data set: 1.26, Accuracy: 0.51\n",
            "Total Time in Testing Model:  16.621034622192383\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}